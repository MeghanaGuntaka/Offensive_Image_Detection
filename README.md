# Offensive_Image_Detection

The widespread availability of offensive and semi-nude images on the internet has emerged as a significant societal challenge, necessitating effective content filtering and moderation solutions. This project addresses this pressing problem by proposing an advanced offensive image detection model based on Convolutional Neural Networks (CNN) employing the VGG architecture. 
Our objective is to develop a robust system capable of accurately distinguishing between safe and unsafe images, providing users with precise safety percentages for uploaded content. This work builds upon and extends the findings of relevant IEEE papers, contributing to the ongoing research in content moderation.
The integration of this solution into online platforms and social media networks can significantly contribute to reducing the dissemination of harmful content, addressing an ongoing societal challenge while respecting ethical and privacy considerations. 

